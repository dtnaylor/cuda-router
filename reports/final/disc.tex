\section{Discussion and Future Work}

\noindent \textbf{Multithreaded CPU Processing.} The comparison of our CPU/GPU
router to the CPU-only baseline is not completely fair. Our CPU-only router
operates in a single thread, yielding misleadingly low performance. Any
CPU-based software router in the real world would certainly spread packet
processing across multiple cores, and we would be surprised if any core
software router were run on a machine with fewer than 16 cores.

A simple extension of our project would be to parallelize our CPU-only packet
processing functions with OpenMP to provide more realistic baseline
measurements.

\medskip \noindent \textbf{Harder Processing Functions.} Even in the final
iteration of our router, the CPU/GPU version only achieves slightly more than
three times the bandwidth of the CPU-only version. Though this is by no means
an improvement to scoff at, the speedup strikes us as being a tad low. We
suspect the cause is that our packet processing functions are not taxing
enough; the harder the processing function, the more benefit we should see from
the massively parallel GPU. This suggests that GPU-based software routers might
be best suited for complex packet processing like IDS filtering (which requires
pattern matching against packet payloads) and IPsec processing (which requires
expensive cryptographic operations).

\medskip \noindent \textbf{Faster Packet I/O.} By far the largest issue we noted
is that generating and gathering packets from click contributes to the majority
of the latency, becoming the dominant part of both CPU and GPU overall
latency. As seen in Figure \ref{fig:iter4}, removing the overhead contributed by
generating and gather packets, our GPU implementation performs much better than
our CPU implementation. This is the same conclusion that the authors of
PacketShader \cite{Han} came to. Thus in their system, they focused on
reimplementing the driver for their NIC to alleviate these issues. In our
framework we could similarly emulate newer NIC technologies (like RDAM) to allow
zero-copy access to DRAM that is memory mapped in the GPU. We could emulate this
by having Click copy packets directly to application DRAM rather than first
sending the packets to the application via a socket.

\medskip \noindent \textbf{Streams.} \TODO{Bruno: Briefly describe CUDA's built-in streams funcitonality}

\medskip \noindent \textbf{Integrated Graphics Processors.} One tempting idea to
explore is the use of integrated graphics processors rather than dedicated
discrete GPUs. Essentially modern processors (Intel Core i-series, etc.) include
a traditional multi-core GPU directly on the processor itself. In essence, this
shifts the position of the GPU from being on the PCI-express bus to being
co-located with the CPU on the quick path interface (QPI). As the QPI can
potentially provide more bus bandwidth to memory, and integrated graphics processor could
potentially provide even higher maximum throughput, as memory constraints are
the biggest source of potential slowdown after packet I/O at the NIC.
